{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime as dttm\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot, rcParams, dates\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, TimeDistributed, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(fname, plot_data = False):\n",
    "    # Read the time series\n",
    "    datats = pd.read_csv(fname, header=0, dayfirst=True, parse_dates=[0], index_col=0, squeeze=True)  # , date_parser=parser\n",
    "\n",
    "    headers = list(datats.columns.values)\n",
    "    headers.insert(0, datats.index.name)\n",
    "\n",
    "    # Convert data to numpy array\n",
    "    data = datats.reset_index().values\n",
    "\n",
    "    # Split data into flow periods, and resample each flow period using a uniform timestep\n",
    "    dt = np.ediff1d(data[:, 0])\n",
    "    fpbreak = dttm.timedelta(hours=1)  # Minimal break between flow periods\n",
    "    dt = dt - fpbreak\n",
    "    ind = np.where(dt - fpbreak > pd.Timedelta(0))[0]\n",
    "    ind = np.r_[ind, len(data)-1]\n",
    "\n",
    "    Nfp = len(ind)  # Number of flow periods\n",
    "    fp = ['None'] * Nfp\n",
    "    n0 = 0\n",
    "    n1 = ind[0]+1\n",
    "    for n in range(Nfp):\n",
    "        # Resample each flow period separately\n",
    "        fpts = datats[n0:n1].resample('T').mean()\n",
    "        fpts = fpts.interpolate(method='linear')\n",
    "        # Save the resampled flow period to a list of numpy arrays\n",
    "        fp[n] = fpts.reset_index().values\n",
    "        #fp[n] = data[n0:n1,:]\n",
    "        n0 = n1\n",
    "        if n+1 < Nfp:\n",
    "            n1 = ind[n+1] + 1\n",
    "\n",
    "    # Plot the graphs\n",
    "    if (plot_data):\n",
    "\n",
    "        color = pyplot.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "        dfmt = dates.DateFormatter('%b %d') # Month day\n",
    "\n",
    "        # Pressure and temperature\n",
    "        fig, ax1 = pyplot.subplots()\n",
    "        ax2 = ax1.twinx()\n",
    "        for n in range(Nfp):\n",
    "            if n == 0:\n",
    "                hl1 = ax1.plot(fp[n][:, 0], fp[n][:, 1], color=color[3], label='Pressure')\n",
    "                hl2 = ax2.plot(fp[n][:, 0], fp[n][:, 2], color=color[4], label='Temperature')\n",
    "            else:\n",
    "                ax1.plot(fp[n][:, 0], fp[n][:, 1], color=color[3])\n",
    "                ax2.plot(fp[n][:, 0], fp[n][:, 2], color=color[4])\n",
    "\n",
    "        ax1.xaxis.set_major_formatter(dfmt)\n",
    "        fig.autofmt_xdate()\n",
    "        ax1.set_ylabel(headers[1], color=color[3])\n",
    "        ax1.tick_params(axis='y', colors=color[3])\n",
    "        headers[2] = headers[2].replace('degC', 'Â°C')\n",
    "        ax2.set_ylabel(headers[2], color=color[4])\n",
    "        ax2.tick_params(axis='y', colors=color[4])\n",
    "\n",
    "        hl = hl1 + hl2\n",
    "        labs = [h.get_label() for h in hl]\n",
    "        ax1.legend(hl, labs, loc=2)\n",
    "        pyplot.title('Pressure and temperature data')\n",
    "        pyplot.show(block=False)\n",
    "        pyplot.savefig('wt_PT.pdf')\n",
    "\n",
    "        # Flow rates\n",
    "        fig, ax1 = pyplot.subplots()\n",
    "        ax2 = ax1.twinx()\n",
    "        for n in range(Nfp):\n",
    "            if n == 0:\n",
    "                hl1 = ax1.plot(fp[n][:, 0], fp[n][:, 3], color=color[1], label='Oil rate')\n",
    "                hl2 = ax1.plot(fp[n][:, 0], fp[n][:, 4], color=color[0], label='Water rate')\n",
    "                hl3 = ax2.plot(fp[n][:, 0], fp[n][:, 5], color=color[2], label='Gas rate')\n",
    "            else:\n",
    "                ax1.plot(fp[n][:, 0], fp[n][:, 3], color=color[1])\n",
    "                ax1.plot(fp[n][:, 0], fp[n][:, 4], color=color[0])\n",
    "                ax2.plot(fp[n][:, 0], fp[n][:, 5], color=color[2])\n",
    "\n",
    "        ax1.xaxis.set_major_formatter(dfmt)\n",
    "        fig.autofmt_xdate()\n",
    "        rheader = headers[3].split()[0] + ' & ' + headers[4]\n",
    "        ax1.set_ylabel(rheader, color=color[1])\n",
    "        ax1.tick_params(axis='y', colors=color[1])\n",
    "        ax2.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "        ax2.set_ylabel(headers[5], color=color[2])\n",
    "        ax2.tick_params(axis='y', colors=color[2])\n",
    "\n",
    "        hl = hl1 + hl2 + hl3\n",
    "        labs = [h.get_label() for h in hl]\n",
    "        ax1.legend(hl, labs, loc=1)\n",
    "        pyplot.title('Flow rates data')\n",
    "        pyplot.show(block=False)\n",
    "        pyplot.savefig('wt_Q.pdf')\n",
    "\n",
    "    # Get the normalization parameters for all data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(data[:,1:]) # Exclude Datetime from normalization\n",
    "\n",
    "    # Normalize every flow period\n",
    "    for n in range(Nfp):\n",
    "        fp[n][:,1:] = scaler.transform(fp[n][:,1:])\n",
    "\n",
    "    return fp, headers, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sequences, shifted by step, for all flow periods fp\n",
    "def define_fp_seq(fp, step, verbose=False):\n",
    "\n",
    "    Nseqmin = max([fp[n].shape[0] for n in FP])\n",
    "    for n in FP:\n",
    "        N = fp[n].shape[0]  # Sequence length for the n-th training flow period\n",
    "        train_frac = 1  # Fraction of data used for training\n",
    "        Ntr = int(train_frac * N)  # Estimate the number of timesteps used for training\n",
    "\n",
    "        Nseq = Ntr // 4  # Length of a training sequence\n",
    "\n",
    "        # Ensure even Nseq to get inp=outp below\n",
    "        if Nseq % 2 != 0:\n",
    "            Nseq = Nseq - 1\n",
    "\n",
    "        if Nseq < 2 or Nseq > Ntr:\n",
    "            print('Please set the training sequence length within [2, ' + repr(Ntr) + ']')\n",
    "            sys.exit(1)\n",
    "\n",
    "        pred_frac = 0.5  # Within a training sequence, fraction of data used for prediction\n",
    "        outp = max(1, int(pred_frac * Nseq))  # Number of timesteps in the output sequence\n",
    "        inp = Nseq - outp  # Number of timesteps in the input training sequence\n",
    "\n",
    "        # Compute the number of training sequences\n",
    "        Nts = int((Ntr - Nseq) / step + 1)\n",
    "        Ntr = Nseq + step * (Nts - 1)  # Adjust Ntr for the specified step & Nts\n",
    "\n",
    "        if verbose:\n",
    "            print('Flow period ' + str(n) + ':')\n",
    "            print('     Length of a training sequence: ' + str(Nseq))\n",
    "            print('     Number of training sequences: ' + str(Nts))\n",
    "            print('     Sequence indentation step: ' + str(step))\n",
    "\n",
    "        if Nseq < Nseqmin:\n",
    "            Nseqmin = Nseq\n",
    "            nmin = n\n",
    "\n",
    "    # Choose the minimal Nseq\n",
    "    Nseq = Nseqmin\n",
    "    if verbose:\n",
    "        print('Choosing min training sequence length of ' + str(Nseq) + ' from flow period ' + str(nmin))\n",
    "\n",
    "    pred_frac = 0.5  # Within a training sequence, fraction of data used for prediction\n",
    "    outp = max(1, int(pred_frac * Nseq))  # Number of timesteps in the output sequence\n",
    "    inp = Nseq - outp  # Number of timesteps in the input training sequence\n",
    "\n",
    "    # Create a list of Nts for all flow periods\n",
    "    Ntsfp = np.zeros(Nfp, dtype=np.int)\n",
    "    for n in FP:\n",
    "        N = fp[n].shape[0]  # Sequence length for the n-th flow period\n",
    "        train_frac = 1  # Fraction of data used for training\n",
    "        Ntr = int(train_frac * N)  # Estimate the number of timesteps used for training\n",
    "        Ntsfp[n] = int((Ntr - Nseq) / step + 1)\n",
    "\n",
    "    return Nseq, Ntsfp, inp, outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(data, features, Nts, step, length, shift):\n",
    "\n",
    "    X = np.zeros((Nts, length, len(features)))\n",
    "    tX = np.tile(data[0,0], (Nts, length))     # Create a 2D timestamp array\n",
    "\n",
    "    for i in range(Nts):\n",
    "        X[i] = data[i*step+shift : i*step+shift+length, features]\n",
    "        tX[i] = data[i*step+shift : i*step+shift+length, 0]\n",
    "\n",
    "    return X, tX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, tX, Y, tY assumed to be normalized to [0, 1]\n",
    "def visualize(X, tX, Y, tY):\n",
    "\n",
    "    Ns = X.shape[0]    # Number of sequences\n",
    "    Nif = X.shape[2]    # Number of input features\n",
    "    Nof = Y.shape[2]    # Number of output features\n",
    "\n",
    "    pyplot.close('all')\n",
    "\n",
    "    # Plot input sequences\n",
    "    squeeze = 0.9\n",
    "    barheight = squeeze * np.minimum(1 / Ns, 0.1)\n",
    "    interbar = 0.1 * barheight\n",
    "    starty = 0.5 + (barheight + interbar) * Ns / 2\n",
    "\n",
    "    f, ax = pyplot.subplots(1, sharex=True)\n",
    "    pyplot.xlim(0, 1)   # Fix the x range to (0, 1)\n",
    "\n",
    "    for i in range(Ns):\n",
    "        for j in range(Nif):\n",
    "            ax.plot(tX[i,:], X[i,:,j], 'b')\n",
    "        for j in range(Nof):\n",
    "            ax.plot(tY[i, :], Y[i, :, j], 'r')\n",
    "\n",
    "    # Add bars to indicate the span of data sequences\n",
    "    startybar = starty\n",
    "    for i in range(Ns):\n",
    "        endybar = startybar - barheight\n",
    "        ax.axhspan(startybar, endybar, xmin=min(tX[i,:]), xmax=max(tX[i,:]), facecolor='g', alpha=0.5)  # Input\n",
    "        ax.axhspan(startybar, endybar, xmin=min(tY[i, :]), xmax=max(tY[i, :]), facecolor='r', alpha=0.5)  # Output\n",
    "        startybar = endybar - interbar\n",
    "\n",
    "    ax.set_title('Data sequences', fontweight='bold')\n",
    "    pyplot.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fp, TFP, inp_features, outp_features, Nseq, Ntsfp, step, inp, outp, model_name):\n",
    "\n",
    "    # Fix random seed for reproducibility\n",
    "    import os\n",
    "    import random\n",
    "    import tensorflow\n",
    "    import keras\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "    session_conf = tensorflow.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    #session_conf = tensorflow.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=8)\n",
    "    tensorflow.set_random_seed(1)\n",
    "    sess = tensorflow.Session(graph=tensorflow.get_default_graph(), config=session_conf)\n",
    "    keras.backend.set_session(sess)\n",
    "\n",
    "    # Model name to save the weights\n",
    "    ilist = ['%d' % i for i in inp_features]\n",
    "    ilist = ''.join(ilist)\n",
    "    olist = ['%d' % i for i in outp_features]\n",
    "    olist = ''.join(olist)\n",
    "    mname = model_name + '_i' + ilist + '_o' + olist\n",
    "\n",
    "    # Generate training sequences for selected flow periods\n",
    "    for n in TFP:\n",
    "        _X, _tX = generate_samples(fp[n], inp_features, Ntsfp[n], step, inp, 0)\n",
    "        _Y, _tY = generate_samples(fp[n], outp_features, Ntsfp[n], step, outp, inp)\n",
    "        # Accumulate sequences from all training periods\n",
    "        if n == 0:\n",
    "            X, tX = _X, _tX\n",
    "            Y, tY = _Y, _tY\n",
    "        else:\n",
    "            X = np.append(X, _X, axis=0)\n",
    "            tX = np.append(tX, _tX, axis=0)\n",
    "            Y = np.append(Y, _Y, axis=0)\n",
    "            tY = np.append(tY, _tY, axis=0)\n",
    "\n",
    "\n",
    "    if model_name == 'LSTM':\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units=10, input_shape=(inp, len(inp_features)), return_sequences=True))\n",
    "        model.add(LSTM(units=10, return_sequences=True))\n",
    "        model.add(LSTM(units=10, return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(len(outp_features))))\n",
    "        model.add(Activation('linear'))\n",
    "        # model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "        history = model.fit(X, Y, batch_size=1, epochs=10, validation_split=0.05)\n",
    "\n",
    "    elif model_name == 'FF':  # Feedforward NN\n",
    "\n",
    "        if len(inp_features) != 1 or len(outp_features) != 1:\n",
    "            print('Feedforward NN is only defined for a single feature.. Exiting..')\n",
    "            return\n",
    "\n",
    "        X = X.reshape(len(X), inp)\n",
    "        Y = Y.reshape(len(Y), outp)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(10, input_shape=(inp,)))\n",
    "        model.add(Dense(10))\n",
    "        model.add(Dense(10))\n",
    "        model.add(Dense(outp))\n",
    "        model.add(Activation('linear'))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        print(model.summary())\n",
    "\n",
    "        history = model.fit(X, Y, batch_size=1, epochs=10, validation_split=0.05)\n",
    "\n",
    "    else:\n",
    "        print('Model not defined.. Exiting..')\n",
    "        return\n",
    "\n",
    "\n",
    "    # Save the model\n",
    "    model.save(mname + '.h5')\n",
    "\n",
    "    # Plotting the convergence history\n",
    "    pyplot.figure(3)\n",
    "    pyplot.semilogy(history.history['loss'])\n",
    "    pyplot.title('model loss')\n",
    "    pyplot.ylabel('loss')\n",
    "    pyplot.xlabel('epoch')\n",
    "    pyplot.show(block=False)\n",
    "\n",
    "    # Save the convergence history\n",
    "    df = pd.DataFrame(history.history['loss'])\n",
    "    df.index.name = 'Epoch'\n",
    "    df.to_csv(mname + '_convergence.csv', header=['loss'])\n",
    "    pyplot.savefig(mname + '_convergence.pdf')\n",
    "\n",
    "    print('Done..')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'squeeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\PhD\\VFM\\test.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/PhD/VFM/test.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m rcParams\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mfigure.autolayout\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m})\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/PhD/VFM/test.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Read and normalize the flow periods\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/PhD/VFM/test.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m fp, headers, scaler \u001b[39m=\u001b[39m read_data(\u001b[39m'\u001b[39;49m\u001b[39mwelltest.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)    \u001b[39m# , plot_data=True\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/PhD/VFM/test.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m inp_features \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m]       \u001b[39m# Indices of columns in data which will be used as output features\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/PhD/VFM/test.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m outp_features \u001b[39m=\u001b[39m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m]   \u001b[39m# Indices of columns in data which will be used as output features\u001b[39;00m\n",
      "\u001b[1;32mf:\\PhD\\VFM\\test.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/PhD/VFM/test.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_data\u001b[39m(fname, plot_data \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/PhD/VFM/test.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Read the time series\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/PhD/VFM/test.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     datats \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(fname, header\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, dayfirst\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, parse_dates\u001b[39m=\u001b[39;49m[\u001b[39m0\u001b[39;49m], index_col\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, squeeze\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)  \u001b[39m# , date_parser=parser\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/PhD/VFM/test.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     headers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(datats\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/PhD/VFM/test.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     headers\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, datats\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mname)\n",
      "\u001b[1;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'squeeze'"
     ]
    }
   ],
   "source": [
    "# Fix the autolayout for matplotlib\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "# Read and normalize the flow periods\n",
    "fp, headers, scaler = read_data('welltest.csv')    # , plot_data=True\n",
    "\n",
    "inp_features = [1, 2]       # Indices of columns in data which will be used as output features\n",
    "outp_features = [3, 4, 5]   # Indices of columns in data which will be used as output features\n",
    "\n",
    "TFP = [0, 1]    # Indices of flow periods, used for training\n",
    "Ntfp = len(TFP) # Number of flow periods, used for training\n",
    "\n",
    "Nfp = len(fp)   # Number of flow periods\n",
    "FP = list(range(Nfp))\n",
    "\n",
    "errFP = set(TFP) - set(FP)\n",
    "if Ntfp > Nfp:\n",
    "    print('Too many training flow periods.. Exiting..')\n",
    "    sys.exit(1)\n",
    "if len(errFP) > 0:\n",
    "    print('Incorrect training flow period(s): ' + errFP + ' Exiting..')\n",
    "    sys.exit(1)\n",
    "\n",
    "# Define sequences, shifted by step, for all flow periods fp\n",
    "step = 1\n",
    "Nseq, Ntsfp, inp, outp = define_fp_seq(fp, step)\n",
    "\n",
    "# Compute the relative forecasting interval\n",
    "DT = pd.Timedelta(0)\n",
    "for i in TFP:\n",
    "    t0 = fp[i][0,0]\n",
    "    t1 = fp[i][-1, 0]\n",
    "    dt = t1 - t0\n",
    "    DT += dt\n",
    "\n",
    "DT = DT.days * 24 * 60 + DT.seconds / 60    # Convert DT to minutes\n",
    "print('Relative forecasting interval: ' + str(outp/DT*100) + '%')\n",
    "\n",
    "# File name for the model\n",
    "model_name = 'LSTM'\n",
    "ilist = ['%d' % i for i in inp_features]\n",
    "ilist = ''.join(ilist)\n",
    "olist = ['%d' % i for i in outp_features]\n",
    "olist = ''.join(olist)\n",
    "tfplist = ['%d' % i for i in TFP]\n",
    "tfplist = ''.join(tfplist)\n",
    "#mname = model_name + '_i' + ilist + '_o' + olist + '_FP' + str(tfplist)\n",
    "mname = model_name + '_i' + ilist + '_o' + olist\n",
    "\n",
    "# Get the trained Keras model\n",
    "train_model = True\n",
    "if train_model:\n",
    "    model = run(fp, TFP, inp_features, outp_features, Nseq, Ntsfp, step, inp, outp, model_name)\n",
    "else:   # Load the previously saved Keras model\n",
    "    model = load_model(mname + '.h5')\n",
    "\n",
    "# Running predictions with the model\n",
    "#step = outp     # Adjusting number of non-overlapping sequences in flow periods\n",
    "step = outp // 2     # Overlap sequences in flow periods\n",
    "Nsfp = np.zeros(Nfp, dtype=np.int)\n",
    "for n in FP:\n",
    "    N = fp[n].shape[0]  # Sequence length for the n-th flow period\n",
    "    Nsfp[n] = int((N - Nseq) / step + 1)    # Number of sequences of length Nseq in fp[n]\n",
    "\n",
    "# Generating the test sequences covering all data, so that the output sequences are non-overlapping\n",
    "for n in FP:\n",
    "    _X, _tX = generate_samples(fp[n], inp_features, Nsfp[n], step, inp, 0)\n",
    "    _Y, _tY = generate_samples(fp[n], outp_features, Nsfp[n], step, outp, inp)\n",
    "    _Yplot, _tplot = generate_samples(fp[n], outp_features, Nsfp[n], step, inp, 0)  # To fill the gap in plotting forecasts at the beginning of each flow period\n",
    "    # Accumulate sequences from all training periods\n",
    "    if n == 0:\n",
    "        X, tX = _X, _tX\n",
    "        Y, tY = _Y, _tY\n",
    "        Yplot, tplot = _Yplot, _tplot\n",
    "    else:\n",
    "        X = np.append(X, _X, axis=0)\n",
    "        tX = np.append(tX, _tX, axis=0)\n",
    "        Y = np.append(Y, _Y, axis=0)\n",
    "        tY = np.append(tY, _tY, axis=0)\n",
    "        Yplot = np.append(Yplot, _Yplot, axis=0)\n",
    "        tplot = np.append(tplot, _tplot, axis=0)\n",
    "\n",
    "# Prediction on all data\n",
    "Ypred = model.predict(X, verbose=0)\n",
    "\n",
    "# Get back the dimensional rates\n",
    "Y -= scaler.min_[2:]\n",
    "Y /= scaler.scale_[2:]\n",
    "Ypred -= scaler.min_[2:]\n",
    "Ypred /= scaler.scale_[2:]\n",
    "Yplot -= scaler.min_[2:]\n",
    "Yplot /= scaler.scale_[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autowell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
